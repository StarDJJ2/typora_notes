# 1.初始化网络权重的作用

初始化网络权重在深度学习中具有关键作用。在训练神经网络时，权重参数是通过优化算法（如梯度下降）不断更新的。权重的初始值对训练过程和最终模型性能有很大影响。以下是初始化网络权重的一些主要目的：

1. **避免对称性问题**：如果所有权重都初始化为相同的值，神经元在训练过程中将学到相同的特征。这会导致网络的容量减小，因为所有神经元都在执行相同的任务。通过随机初始化权重，我们可以打破这种对称性，使得每个神经元学习不同的特征。

2. **梯度消失/梯度爆炸问题**：如果权重值过大或过小，可能导致训练过程中的梯度消失（变得非常小）或梯度爆炸（变得非常大）。这会影响训练速度和模型的收敛能力。通过选择合适的权重初始化策略，我们可以降低梯度消失和梯度爆炸问题的风险。

3. **加速收敛**：合适的权重初始化可以使网络更快地收敛。这意味着在训练过程中，我们需要更少的迭代次数来达到最优或近似最优解。

4. **提高模型性能**：使用合适的权重初始化策略可以提高模型在验证和测试集上的性能。一个好的权重初始值可以使模型更容易从数据中学习和泛化。

有多种权重初始化策略，例如：

- 随机初始化：权重被随机分配，通常使用均匀分布或正态分布。
- Xavier/Glorot 初始化：根据输入和输出神经元的数量，将权重初始化为特定范围内的值。这个策略适用于 Sigmoid 和 Tanh 激活函数。
- He 初始化：类似于 Xavier/Glorot 初始化，但考虑了 ReLU 激活函数的特性。

选择合适的权重初始化策略取决于网络的结构和激活函数。通过为网络选择适当的权重初始化，我们可以提高模型性能并减少训练时间。

## 1.初始化权重实例

```python
import torch
import torch.nn as nn
from torchvision.models import resnet34

def init_weights_kaiming_normal(m):
    if isinstance(m, nn.Conv2d):
        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
    elif isinstance(m, nn.BatchNorm2d):
        nn.init.constant_(m.weight, 1)
        nn.init.constant_(m.bias, 0)
    elif isinstance(m, nn.Linear):
        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
        nn.init.constant_(m.bias, 0)

model = resnet34(pretrained=False)  # 创建一个未经预训练的ResNet34模型
model.apply(init_weights_kaiming_normal)  # 使用kaiming_normal_方法初始化权重
```

上述代码首先定义了一个函数`init_weights_kaiming_normal`，在这个函数中，我们根据层的类型（`nn.Conv2d`，`nn.BatchNorm2d`和`nn.Linear`）使用`kaiming_normal_`方法初始化权重。然后，我们创建一个未经预训练的ResNet34模型，并使用<font color='red'>model.apply()</font>`方法将`init_weights_kaiming_normal`函数应用于整个网络，从而初始化所有权重。

# 2.初始化权重后出现 `train_loss=nan` 和 `val_loss=nan` 的情况

查看网络各层的参数情况：[(1条消息) Pytorch(六)(模型参数的遍历) —— model.parameters() & model.named_parameters() & model.state_dict()_hxxjxw的博客-CSDN博客](https://blog.csdn.net/hxxjxw/article/details/107717031?ops_request_misc=%7B%22request%5Fid%22%3A%22162781022916780264057891%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&request_id=162781022916780264057891&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-3-107717031.pc_search_result_before_js&utm_term=model.named_parameters() ,model.parameters() ,model.state_dict().items()&spm=1018.2226.3001.4187)

出现 `train_loss=nan` 和 `val_loss=nan` 的情况可能有多种原因。以下是一些建议，以帮助您找出可能的问题并解决它们：

1. **学习率过高**：如果学习率设置得过高，优化器可能会在梯度下降过程中跳过最优解，导致损失函数值无法收敛，甚至可能变为 NaN。尝试降低学习率，并观察损失是否正常。<font color='red'>（较为常见）</font>

2. **数据预处理问题**：检查您的数据预处理流程，确保输入数据没有异常值或不正确的缩放。例如，图像数据通常需要归一化到 [0, 1] 或 [-1, 1] 范围内。错误的数据预处理可能导致模型在训练过程中收敛到错误的解或无法收敛。   <font color='red'>（之前的错误就有这个原因，换了个数据加载的方式后，这个错误便消失了）</font>

3. **数值不稳定性**：某些操作可能导致数值不稳定，例如除以接近零的值。检查您的模型架构和损失函数，确保没有执行可能导致数值不稳定的操作。

4. **模型复杂度**：过于复杂的模型可能导致梯度消失或梯度爆炸问题，从而导致损失变为 NaN。您可以尝试使用更简单的模型、添加梯度截断或使用批量归一化层来解决这个问题。

5. **损失函数问题**：确保您的损失函数适用于您的问题，且在数值上稳定。例如，如果您的问题是分类任务，请不要使用均方误差损失；相反，应使用交叉熵损失。

6. **权重初始化问题**：尽管在前面的代码中我们使用了 He 初始化，但有时不同的模型可能需要不同的初始化策略。您可以尝试其他权重初始化方法，如 Xavier/Glorot 初始化，以查看它们是否会改善训练和验证损失。

要确定问题的具体原因，建议您尝试以上建议并仔细检查代码。根据问题的具体情况，您可能需要调整模型、数据预处理流程或训练参数以解决损失为 NaN 的问题。

## 自己尝试的解决方法：

### 1.使用的官方权重可能已经被之前其他的文件训练覆盖了，去缓存路径，把官方权重删除，重新下载加载

# 3.CPU占用率过高----top命令进行查看

在运行深度学习神经网络模型时，CPU占用率过高可能有以下原因：

1. **计算密集型任务**：深度学习模型通常包含大量参数和复杂的计算图，需要进行大量的矩阵运算。在训练或推理过程中，CPU需要完成这些计算，导致占用率上升。

2. **多线程和多进程**：深度学习框架（如TensorFlow 和 PyTorch）会尽可能利用多线程和多进程来加速计算。当有多个核心和线程可用时，框架会尝试在所有资源上分配任务，从而增加CPU占用率。

3. **数据加载和预处理**：在训练深度学习模型时，数据加载和预处理（如数据增强）通常在CPU上执行。如果数据加载和预处理的速度跟不上模型训练的速度，CPU资源可能会成为瓶颈。

4. **内存不足**：如果系统内存不足，操作系统可能会使用硬盘上的虚拟内存，导致运行速度变慢。在这种情况下，CPU资源利用率可能会上升，因为需要花费更多时间在内存管理上。

为了降低CPU占用率，可以尝试以下方法：

1. **使用GPU加速**：如果有可用的GPU资源，可以将深度学习模型部署到GPU上以获得更好的性能。大多数深度学习框架都提供GPU支持。

2. **优化数据加载和预处理**：使用数据加载器的多线程或多进程功能以更高效地加载和预处理数据。同时，确保数据增强和其他预处理操作在GPU上执行（如果可用）。

3. **模型优化**：尝试使用更小的模型或减少模型复杂度，以降低计算需求。可以使用模型压缩技术（如权重剪枝、量化和知识蒸馏）来减小模型大小，同时保持性能。

4. **调整批量大小**：减小训练批量大小可以降低内存需求和计算负载，但可能会影响模型收敛速度和准确性。需要权衡这些因素来找到合适的批量大小。

   ## 原因：数据采样点的突然增大，触发了多线程机制

   torch.set_num_threads( )是PyTorch中的一个函数，用于设置PyTorch的线程数。它的作用是控制PyTorch在执行计算时使用的CPU线程数，从而提高计算效率。可以通过设置torch.set_num_threads(n)来指定使用的线程数，其中n为整数值。

   

# 4.回归预测

## sklearn.metrics.r2_score  详细解释下它的作用原理

`sklearn.metrics.r2_score` 是一个评估回归模型性能的指标，称为 R² 分数（确定系数）。R² 分数可以解释为模型预测的目标变量的方差占总方差的比例。换句话说，它表示了模型捕获的数据中的可变性程度。R² 分数的值介于 0 和 1 之间，但在某些情况下，当模型非常糟糕时，它也可能为负。

CSDN说明：

https://blog.csdn.net/qq_45355712/article/details/129195716#:~:text=R2

R² 分数表示模型解释的目标变量方差占总方差的比例。值越接近 1，表示模型解释了更多的方差，性能越好。值越接近 0，表示模型解释的方差较少，性能较差。

总结一下，R² 分数是衡量回归模型预测能力的一个指标。它表示了模型捕获的数据中的可变性程度。在 scikit-learn 中，您可以使用 `sklearn.metrics.r2_score` 函数轻松计算 R² 分数。

## sklearn.metrics.mean_squared_error  详细解释下它的作用原理

`sklearn.metrics.mean_squared_error`是一个评价函数，用于计算均方误差（Mean Squared Error, MSE）。它的主要作用是衡量实际观测值与模型预测值之间的平均平方差。

均方误差是一种常见的回归分析误差度量，将各个点到回归直线的距离（误差）平方，然后求和平均，得到的结果就是MSE。其数学公式为：

MSE = 1/n * Σ(y_i - ŷ_i)^2

其中，y_i 是实际观测值， ŷ_i 是模型预测值，n 是样本的数量。

使用Python sklearn库的mean_squared_error函数，可以很容易地计算MSE。例如：

```python
from sklearn.metrics import mean_squared_error

y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]

mse = mean_squared_error(y_true, y_pred)

print(mse)
```

在以上代码中， `y_true` 是真实的标签值， `y_pred` 是模型预测的值， `mean_squared_error(y_true, y_pred)` 就会计算出这两个列表对应的MSE。

要注意的是，MSE对大的误差值（离群点）更为敏感，因为在计算过程中会将误差进行平方，所以在存在离群点的情况下可能会放大其影响。在某些情况下，可能会用平均绝对误差（MAE）或均方根误差（RMSE）作为替代的误差度量方式。



## sklearn.metrics.mean_squared_error得出的值很大，而R2 Score得出的值显示出模型的预测性能很好  这是怎么回事？

这种情况下，可能是因为你的预测问题涉及的数值范围较大，所以在均方误差（MSE）看起来非常高，而R²分数则没有受数值尺度的影响。

均方误差（MSE）是实际观测值与预测值差的平方和的平均值。如果数据的尺度（即值的范围）很大，即使预测相当准确，MSE的值也可能会很高。这是由MSE的计算方式决定的，因为差的平方在数值较大时会变得更大。

而R²分数（也称为决定系数）测量的是我们的模型相对于最简单的基准模型（即输出值就是目标变量的平均值的模型）的改进程度。其值范围在0到1之间，1表示模型预测完全正确，0表示模型没有超过基准模型。R²分数并不直接依赖于目标变量的尺度，所以即使在目标变量范围大的情况下，也能给出良好的模型性能判断。

所以，你可以同时看这两个指标。MSE更直观地反映模型预测错误的数量级，而R²分数则反映模型相对于最简单模型的预测改进程度。

### 一般在数值尺度较小的时候才使用MSE，比如回归预测的值限定在0-5之间，而在我做PM2.5回归预测这里，回归预测的值甚至可以达到300+，数值尺度较大，所以不适合使用MSE，反而用R2 Score比较合适

# 5.torchsummary中的summary要使用在model.to（device）后面，即都在cuda上

# 6.图像归一化问题

对RGB图片而言，数据范围是[0-255]的，需要先经过ToTensor除以255归一化到[0,1]之后，再通过Normalize计算过后，将数据归一化到[-1,1]