# 1.两次不同的训练结果

1.

![image-20230710111133259](C:\Users\25075\AppData\Roaming\Typora\typora-user-images\image-20230710111133259.png)

2.

![image-20230710111631836](C:\Users\25075\AppData\Roaming\Typora\typora-user-images\image-20230710111631836.png)

# 2.设置随机种子

## 1.加入torch.manual_seed(11)后（无效）

1.![image-20230710112934921](C:\Users\25075\AppData\Roaming\Typora\typora-user-images\image-20230710112934921.png)

2.

![image-20230710113501082](C:\Users\25075\AppData\Roaming\Typora\typora-user-images\image-20230710113501082.png)

## 2.加入seed_everything和worker_init_fn函数后（结果成功复现）

### 1.seed_everything:

```python
#---------------------------------------------------#
#   设置种子
#---------------------------------------------------#
def seed_everything(seed=11):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True    #用于保证CUDA 卷积运算的结果确定
    torch.backends.cudnn.benchmark = False		#是用于保证数据变化的情况下，减少网络效率的变化。为True的话容易降低网络效率。

```

### 2.worker_init_fn:

```python
#---------------------------------------------------#
#   设置Dataloader的种子
#---------------------------------------------------#
def worker_init_fn(worker_id, rank, seed):
    worker_seed = rank + seed
    random.seed(worker_seed)
    np.random.seed(worker_seed)
    torch.manual_seed(worker_seed)
#这里我在使用的时候去掉了rank参数和wirker_seed = rank + seed这行，然后将后面三行内的参数都改为了seed
#rank一般用在多卡的情况下
```

1.

![image-20230710144726522](C:\Users\25075\AppData\Roaming\Typora\typora-user-images\image-20230710144726522.png)

2.

![image-20230710145338094](C:\Users\25075\AppData\Roaming\Typora\typora-user-images\image-20230710145338094.png)

# 3.如何取消随机种子？

使用torch.seed( )方法

[torch中的随机数种子-阿里云开发者社区 (aliyun.com)](https://developer.aliyun.com/article/1190890#:~:text=要取消 PyTorch 中的随机种子，可以使用 torch.seed (),函数，它可以将随机种子设置为当前时间戳，从而实现取消之前设置的随机种子。 以下是一个示例代码，展示了如何使用 torch.seed () 函数取消之前设置的随机种子：)